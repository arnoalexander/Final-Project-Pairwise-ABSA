{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Tools\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import definition\n",
    "from ner import Reader, Extractor, BiLstmCrfTagger, UnaryBatchGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "\n",
    "raw_data = Reader.read_file(definition.DATA_PAIRED_SAMPLE)\n",
    "index = np.arange(len(raw_data))\n",
    "np.random.shuffle(index)\n",
    "index_train = index[:int(train_ratio * len(raw_data))]\n",
    "index_test = index[int(train_ratio * len(raw_data)):]\n",
    "raw_data_train = np.array(raw_data)[index_train].tolist()\n",
    "raw_data_test = np.array(raw_data)[index_test].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n",
      "675\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_data_train))\n",
    "print(len(raw_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|██████████████████████████████████████████████████████████| 2023/2023 [00:00<00:00, 63255.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding model not found. It will be generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|████████████████████████████████████████████████████████████| 675/675 [00:00<00:00, 56280.92it/s]\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor(embedding_filename=definition.MODEL_EMBEDDING_FASTTEXT)\n",
    "X_train, y_train = extractor.extract_data(raw_data_train)\n",
    "X_test, y_test = extractor.extract_data(raw_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor.save_encoder_model(definition.MODEL_ENCODING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3137)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3137 100 50 5\n"
     ]
    }
   ],
   "source": [
    "n_features = X_train[0].shape[1]\n",
    "n_lstm_unit = 100\n",
    "n_distributed_dense = 50\n",
    "n_tags = 5\n",
    "\n",
    "print(n_features, n_lstm_unit, n_distributed_dense, n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLstmCrfTagger(n_features=n_features, n_lstm_unit=n_lstm_unit, n_distributed_dense=n_distributed_dense, n_tags=n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = UnaryBatchGenerator(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 163s - loss: 0.4658 - crf_accuracy: 0.8180\n",
      "Epoch 2/2\n",
      " - 161s - loss: 0.1274 - crf_accuracy: 0.9039\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, epochs=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>crf_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.465845</td>\n",
       "      <td>0.818020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.127354</td>\n",
       "      <td>0.903864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  crf_accuracy\n",
       "0  0.465845      0.818020\n",
       "1  0.127354      0.903864"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(definition.MODEL_NER_KERAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 675/675 [00:18<00:00, 36.73it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "for item in tqdm(X_test):\n",
    "    pred.append(model.predict(np.array([item]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = extractor.convert_y_matrix_to_label(pred).tolist()\n",
    "y_test_label = extractor.convert_y_matrix_to_label(y_test).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label_flatten = [token for sentence in pred_label for token in sentence]\n",
    "y_test_label_flatten = [token for sentence in y_test_label for token in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    B-ASPECT       0.90      0.78      0.84      1283\n",
      " B-SENTIMENT       0.89      0.88      0.89      1708\n",
      "    I-ASPECT       0.90      0.58      0.70       411\n",
      " I-SENTIMENT       0.81      0.79      0.80       810\n",
      "           O       0.90      0.95      0.92      6515\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     10727\n",
      "   macro avg       0.88      0.80      0.83     10727\n",
      "weighted avg       0.89      0.89      0.89     10727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_label_flatten, pred_label_flatten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
